{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f740f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by Alexander Bolejack & Austin Roddy\n",
    "# Illinois Institute of Technology\n",
    "# Intllgnc Txt Analys Knwldg Mgm (CS-481-01), Spring 2022\n",
    "# Programming Assignment 2 - Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f81af55-9a47-4e68-bf37-dd69c1e0d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inport the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords as sw\n",
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d879f01-5562-42a3-85bb-135d70a0f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data, and drop the unnecessary columns, remove non-alphabetical characters(first pass)\n",
    "full_dataset_df = pd.read_csv (\"dataset.csv\")\n",
    "full_dataset_df.drop('app_id', inplace=True, axis=1)\n",
    "full_dataset_df.drop('app_name', inplace=True, axis=1)\n",
    "full_dataset_df.drop('review_votes', inplace=True, axis=1)\n",
    "full_dataset_df.rename(columns={'review_text': 'text', 'review_score': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d035f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate messages in entries in the dataset\n",
    "duplicates = full_dataset_df.duplicated(subset='text', keep='first')\n",
    "full_dataset_df = full_dataset_df.drop(full_dataset_df[duplicates].index)\n",
    "\n",
    "# I wouldnt trust this function HAHAHAHA it deletes 1.6 million rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c7d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the labels if -1 switch to 0\n",
    "full_dataset_df['label'] = full_dataset_df['label'].replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the dataframe\n",
    "randomized_full_dataset_df = full_dataset_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4657d4",
   "metadata": {},
   "source": [
    "### Lets provide some raw numbers\n",
    "\n",
    "##### We want to know how many positive and negative reviews there, as a percent and total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad505f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1ab8b3b10a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.catplot(x='label', kind='count', data=randomized_full_dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9bc78f",
   "metadata": {},
   "source": [
    "# Now we handle our data, clean the text, split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a550077-77e7-4add-a737-4cae17ad13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (90% training, 10% testing) (and randomize... again...? *shrug*)\n",
    "training_dataset_df = randomized_full_dataset_df.sample(frac=0.9,random_state=200)\n",
    "testing_dataset_df = randomized_full_dataset_df.drop(training_dataset_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0874499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both pos and neg versions of training and testing sets (4 sets)\n",
    "training_pos_dataset_df = training_dataset_df[training_dataset_df['label'] == 1]\n",
    "training_neg_dataset_df = training_dataset_df[training_dataset_df['label'] == 0]\n",
    "testing_pos_dataset_df = testing_dataset_df[testing_dataset_df['label'] == 1]\n",
    "testing_neg_dataset_df = testing_dataset_df[testing_dataset_df['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb787a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# Convert ALL text rows to string, if not already string (this was causing issues which is why im now converting to string)\n",
    "%%capture\n",
    "training_pos_dataset_df['text'] = training_pos_dataset_df['text'].astype(str)\n",
    "training_neg_dataset_df['text'] = training_neg_dataset_df['text'].astype(str)\n",
    "testing_pos_dataset_df['text'] = testing_pos_dataset_df['text'].astype(str)\n",
    "testing_neg_dataset_df['text'] = testing_neg_dataset_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424ef08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# Lowercase ALL sets\n",
    "# Ignore the output warnings, or better yet, disable them. >:) (this is a bit of a hack, but it works)\n",
    "%%capture\n",
    "training_pos_dataset_df.loc[:,'text'] = training_pos_dataset_df.loc[:,'text'].apply(lambda x: x.lower())\n",
    "training_neg_dataset_df.loc[:,'text'] = training_neg_dataset_df.loc[:,'text'].apply(lambda x: x.lower())\n",
    "testing_pos_dataset_df.loc[:,'text'] = testing_pos_dataset_df.loc[:,'text'].apply(lambda x: x.lower())\n",
    "testing_neg_dataset_df.loc[:,'text'] = testing_neg_dataset_df.loc[:,'text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cddb18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe rows to lists\n",
    "training_pos_dataset_list = training_pos_dataset_df['text'].tolist()\n",
    "training_neg_dataset_list = training_neg_dataset_df['text'].tolist()\n",
    "testing_pos_dataset_list = testing_pos_dataset_df['text'].tolist()\n",
    "testing_neg_dataset_list = testing_neg_dataset_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8781e34",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git\\CS440\\CS481-Final-Project-Programming-Assignment-2\\programming-assignment-2-wow.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/CS440/CS481-Final-Project-Programming-Assignment-2/programming-assignment-2-wow.ipynb#ch0000014?line=4'>5</a>\u001b[0m testing_neg_dataset_list_alpha_cleaned \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/CS440/CS481-Final-Project-Programming-Assignment-2/programming-assignment-2-wow.ipynb#ch0000014?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(training_pos_dataset_list)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Git/CS440/CS481-Final-Project-Programming-Assignment-2/programming-assignment-2-wow.ipynb#ch0000014?line=8'>9</a>\u001b[0m     training_pos_dataset_list_alpha_cleaned\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([ch \u001b[39mfor\u001b[39;00m ch \u001b[39min\u001b[39;00m training_pos_dataset_list[i] \u001b[39mif\u001b[39;00m ch\u001b[39m.\u001b[39misalpha() \u001b[39mor\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/CS440/CS481-Final-Project-Programming-Assignment-2/programming-assignment-2-wow.ipynb#ch0000014?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(training_neg_dataset_list)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/CS440/CS481-Final-Project-Programming-Assignment-2/programming-assignment-2-wow.ipynb#ch0000014?line=11'>12</a>\u001b[0m     training_neg_dataset_list_alpha_cleaned\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([ch \u001b[39mfor\u001b[39;00m ch \u001b[39min\u001b[39;00m training_neg_dataset_list[i] \u001b[39mif\u001b[39;00m ch\u001b[39m.\u001b[39misalpha() \u001b[39mor\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Remove all non-alphabetical characters\n",
    "training_pos_dataset_list_alpha_cleaned = []\n",
    "training_neg_dataset_list_alpha_cleaned = []\n",
    "testing_pos_dataset_list_alpha_cleaned = []\n",
    "testing_neg_dataset_list_alpha_cleaned = []\n",
    "\n",
    "\n",
    "for i in range(len(training_pos_dataset_list)):\n",
    "    training_pos_dataset_list_alpha_cleaned.append(''.join([ch for ch in training_pos_dataset_list[i] if ch.isalpha() or ch == ' ']))\n",
    "\n",
    "for i in range(len(training_neg_dataset_list)):\n",
    "    training_neg_dataset_list_alpha_cleaned.append(''.join([ch for ch in training_neg_dataset_list[i] if ch.isalpha() or ch == ' ']))\n",
    "\n",
    "for i in range(len(testing_pos_dataset_list)):\n",
    "    testing_pos_dataset_list_alpha_cleaned.append(''.join([ch for ch in testing_pos_dataset_list[i] if ch.isalpha() or ch == ' ']))\n",
    "\n",
    "for i in range(len(testing_neg_dataset_list)):\n",
    "    testing_neg_dataset_list_alpha_cleaned.append(''.join([ch for ch in testing_neg_dataset_list[i] if ch.isalpha() or ch == ' ']))\n",
    "\n",
    "# wow i cant believe that worked?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each list\n",
    "training_pos_dataset_list_alpha_cleaned_tokenized = []\n",
    "training_neg_dataset_list_alpha_cleaned_tokenized = []\n",
    "testing_pos_dataset_list_alpha_cleaned_tokenized = []\n",
    "testing_neg_dataset_list_alpha_cleaned_tokenized = []\n",
    "\n",
    "\n",
    "for i in range(len(training_pos_dataset_list_alpha_cleaned)):\n",
    "    training_pos_dataset_list_alpha_cleaned_tokenized += [training_pos_dataset_list_alpha_cleaned[i].split()]\n",
    "\n",
    "for i in range(len(training_neg_dataset_list_alpha_cleaned)):\n",
    "    training_neg_dataset_list_alpha_cleaned_tokenized += [training_neg_dataset_list_alpha_cleaned[i].split()]\n",
    "\n",
    "for i in range(len(testing_pos_dataset_list_alpha_cleaned)):\n",
    "    testing_pos_dataset_list_alpha_cleaned_tokenized += [testing_pos_dataset_list_alpha_cleaned[i].split()]\n",
    "\n",
    "for i in range(len(testing_neg_dataset_list_alpha_cleaned)):\n",
    "    testing_neg_dataset_list_alpha_cleaned_tokenized += [testing_neg_dataset_list_alpha_cleaned[i].split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed = []\n",
    "training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed = []\n",
    "testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed = []\n",
    "testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed = []\n",
    "stop_words = set(sw.words('english'))\n",
    "\n",
    "# for i in training_pos_dataset_list_alpha_cleaned_tokenized:\n",
    "#     words = []\n",
    "#     for w in i:\n",
    "#         if w not in stop_words:\n",
    "#             words.append(w)\n",
    "#     training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed += [words]\n",
    "training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed = training_pos_dataset_list_alpha_cleaned_tokenized\n",
    "\n",
    "# for i in training_neg_dataset_list_alpha_cleaned_tokenized:\n",
    "#     words = []\n",
    "#     for w in i:\n",
    "#         if w not in stop_words:\n",
    "#             words.append(w)\n",
    "#     training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed += [words]\n",
    "training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed = training_neg_dataset_list_alpha_cleaned_tokenized\n",
    "\n",
    "# for i in testing_pos_dataset_list_alpha_cleaned_tokenized:\n",
    "#     words = []\n",
    "#     for w in i:\n",
    "#         if w not in stop_words:\n",
    "#             words.append(w)\n",
    "#     testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed += [words]\n",
    "testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed = testing_pos_dataset_list_alpha_cleaned_tokenized\n",
    "\n",
    "# for i in testing_neg_dataset_list_alpha_cleaned_tokenized:\n",
    "#     words = []\n",
    "#     for w in i:\n",
    "#         if w not in stop_words:\n",
    "#             words.append(w)\n",
    "#     testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed += [words]  \n",
    "testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed = testing_neg_dataset_list_alpha_cleaned_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17caf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmed each set:\n",
    "ps = PorterStemmer()\n",
    "\n",
    "training_pos_dataset_list_alpha_cleaned_stemmed = []\n",
    "training_neg_dataset_list_alpha_cleaned_stemmed = []\n",
    "testing_pos_dataset_list_alpha_cleaned_stemmed = []\n",
    "testing_neg_dataset_list_alpha_cleaned_stemmed = []\n",
    "\n",
    "# for i in range(len(training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed)):\n",
    "#     words = []\n",
    "#     for w in range(len(training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i])):\n",
    "#         words.append(ps.stem(training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i][w]))\n",
    "#     training_pos_dataset_list_alpha_cleaned_stemmed += [words]\n",
    "\n",
    "# for i in range(len(training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed)):\n",
    "#     words = []\n",
    "#     for w in range(len(training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i])):\n",
    "#         words.append(ps.stem(training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i][w]))\n",
    "#     training_neg_dataset_list_alpha_cleaned_stemmed += [words]\n",
    "\n",
    "# for i in range(len(testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed)):\n",
    "#     words = []\n",
    "#     for w in range(len(testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i])):\n",
    "#         words.append(ps.stem(testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i][w]))\n",
    "#     testing_pos_dataset_list_alpha_cleaned_stemmed += [words]\n",
    "\n",
    "\n",
    "# for i in range(len(testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed)):\n",
    "#     words = []\n",
    "#     for w in range(len(testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i])):\n",
    "#         words.append(ps.stem(testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed[i][w]))\n",
    "#     testing_neg_dataset_list_alpha_cleaned_stemmed += [words]\n",
    "\n",
    "\n",
    "training_pos_dataset_list_alpha_cleaned_stemmed = training_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed\n",
    "training_neg_dataset_list_alpha_cleaned_stemmed =training_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed\n",
    "testing_pos_dataset_list_alpha_cleaned_stemmed =testing_pos_dataset_list_alpha_cleaned_tokenized_stopwords_removed\n",
    "testing_neg_dataset_list_alpha_cleaned_stemmed = testing_neg_dataset_list_alpha_cleaned_tokenized_stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932176ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to flatten our training for the bayes model\n",
    "training_pos_flat = flat_list = [item for sublist in training_pos_dataset_list_alpha_cleaned_stemmed for item in sublist]\n",
    "training_neg_flat = flat_list = [item for sublist in training_neg_dataset_list_alpha_cleaned_stemmed for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8f1d6",
   "metadata": {},
   "source": [
    "### With clean data now, we can make our Bayes Model\n",
    "##### For this, we can get work counts over the total number of words for each class\n",
    "##### Using these values, as well as the probability of the class, we can make our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0813f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability of class\n",
    "probability_pos = len(training_pos_dataset_df)/ len(training_dataset_df)\n",
    "probability_neg = len(training_neg_dataset_df)/ len(training_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1798f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total vocabulary size\n",
    "total_vocab_size = len(set(training_pos_flat + training_neg_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total count of words for each class\n",
    "pos_denom = len(training_pos_flat)\n",
    "neg_denom = len(training_neg_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdefacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get counts of the words for each class\n",
    "pos_nom = FreqDist(training_pos_flat)\n",
    "neg_nom = FreqDist(training_neg_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get information about smoothing. Simple laplace +1\n",
    "pos_vocab_size = len(pos_nom)\n",
    "neg_vocab_size = len(neg_nom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(probability, denom, total_vocab_size, nom, name):\n",
    "    with open(name, 'w') as f:\n",
    "        f.write(str(probability) + '\\n')\n",
    "        f.write(str(denom) + '\\n')\n",
    "        f.write(str(total_vocab_size) + '\\n\\n')\n",
    "        for i in list(nom.items()):\n",
    "            f.write(str(i[0]) +' ' + str(i[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edde397",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(probability_pos, pos_denom, total_vocab_size, pos_nom, 'pos_prob.txt')\n",
    "save_model(probability_neg, neg_denom, total_vocab_size, neg_nom, 'neg_prob.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file):\n",
    "    model = open(file, 'r')\n",
    "    Lines = model.readlines()\n",
    "    count = 0\n",
    "    wourd_count_dict = {}\n",
    "    for line in Lines:\n",
    "        if count == 0:\n",
    "            class_probability = line\n",
    "        elif count == 1:\n",
    "            denominator = line\n",
    "        elif count == 2:\n",
    "            vocab_size = line\n",
    "        else:\n",
    "            line_split = line.split()\n",
    "            if len(line_split) == 2:\n",
    "                wourd_count_dict[line_split[0]] = int(line_split[1])\n",
    "        count = count + 1\n",
    "\n",
    "    return float(class_probability), int(denominator), int(vocab_size), wourd_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93a28e",
   "metadata": {},
   "source": [
    "### Lets have an inference function\n",
    "\n",
    "##### Takes in a list of strings, that has aready been tokenized etc,\n",
    "##### Returns the predicted class, 1 or -1\n",
    "##### Optional print value, enabled by default\n",
    "\n",
    "##### We also need to make sure a sentence passed is normalized, So we have a noramlize sentence funcion that takes a sentence and turns it into the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sentence_precoessed,prob_pos, pos_denom, total_vocab_size, pos_nom,prob_neg, neg_denom, neg_nom, p_print=True):\n",
    "    pos_value = 1\n",
    "    neg_value = 1\n",
    "    for word in sentence_precoessed:\n",
    "        if word in pos_nom:\n",
    "            pos_value = pos_value + np.log( (pos_nom[word]+1) / (pos_denom+total_vocab_size) )\n",
    "        elif(word in neg_nom):\n",
    "            pos_value = pos_value + np.log( 1 / (pos_denom+total_vocab_size) )\n",
    "        if word in neg_nom:  \n",
    "            neg_value = neg_value + np.log( ( neg_nom[word]+1) / (neg_denom+total_vocab_size) )\n",
    "        elif(word in pos_nom):\n",
    "            neg_value = neg_value + np.log( 1 / (neg_denom+total_vocab_size) )\n",
    "\n",
    "    pos_value = pos_value + np.log(prob_pos)\n",
    "    neg_value = neg_value + np.log(prob_neg)\n",
    "\n",
    "    if p_print:\n",
    "        print('Positive review prediction: ' + str(pos_value))\n",
    "        print('Negative review prediction: ' + str(neg_value))\n",
    "\n",
    "    if pos_value >= neg_value:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentence(sentence):\n",
    "    ps = PorterStemmer()\n",
    "    sentence = sentence.lower()\n",
    "    new_sentence = []\n",
    "    new_sentence.append(''.join([ch for ch in sentence if ch.isalpha() or ch == ' ']))\n",
    "    new_sentence = new_sentence[0].split()\n",
    "\n",
    "    # stop_words = set(sw.words('english'))\n",
    "    # sentence_no_stop_words = []\n",
    "    # for i in new_sentence:\n",
    "    #     if i not in stop_words:\n",
    "    #         sentence_no_stop_words.append(i)\n",
    "\n",
    "    # sentence_stemmed = []\n",
    "\n",
    "    # for i in range(len(new_sentence)):\n",
    "    #     sentence_stemmed.append(ps.stem(new_sentence[i]))\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From a sentence to input\n",
    "sentence = \"0/10 made sex no longer enjoyable\"\n",
    "sentence_normalized = normalize_sentence(sentence)\n",
    "print(sentence_normalized)\n",
    "class_prob_pos, denom_pos, total_vocab_size, wourd_dict_pos = load_model('pos_prob.txt')\n",
    "class_prob_neg, denom_neg, total_vocab_size, wourd_dict_neg = load_model('neg_prob.txt')\n",
    "prediction = inference(sentence_normalized, class_prob_pos, denom_pos, total_vocab_size, wourd_dict_pos, class_prob_neg, denom_neg, wourd_dict_neg)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32488710",
   "metadata": {},
   "source": [
    "### We Test our Model\n",
    "\n",
    "##### Run all the test sentences through our created model\n",
    "##### Then we get prediction vs actual\n",
    "##### We then have metric to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "class_prob_pos, denom_pos, total_vocab_size, wourd_dict_pos = load_model('pos_prob.txt')\n",
    "class_prob_neg, denom_neg, total_vocab_size, wourd_dict_neg = load_model('neg_prob.txt')\n",
    "\n",
    "for sentence in testing_pos_dataset_list_alpha_cleaned_stemmed:\n",
    "    prediction = inference(sentence, class_prob_pos, denom_pos, total_vocab_size, wourd_dict_pos, class_prob_neg, denom_neg, wourd_dict_neg, p_print=False)\n",
    "    if prediction == 1:\n",
    "        tp = tp + 1\n",
    "    else:\n",
    "        fn = fn + 1\n",
    "\n",
    "for sentence in testing_neg_dataset_list_alpha_cleaned_stemmed:\n",
    "    prediction = inference(sentence, class_prob_pos, denom_pos, total_vocab_size, wourd_dict_pos, class_prob_neg, denom_neg, wourd_dict_neg, p_print=False)\n",
    "    if prediction == -1:\n",
    "        tn = tn + 1\n",
    "    else:\n",
    "        fp = fp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addebcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(tp, fp, fn, tn):\n",
    "    c_matrix = [ [tp, fn], [fp, tn] ]\n",
    "\n",
    "    df_cm = pd.DataFrame(c_matrix, index = [i for i in ['TP', 'FP'] ], columns = [i for i in ['FP','TN'] ])\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tp+fp+fn)\n",
    "    error_rate = (fp+fn)/(tp+tp+fp+fn)\n",
    "    recall = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    precision = tp/(tp+fp)\n",
    "    neg_pred_val = tn/(tn+fn)\n",
    "    f_score = 2*(precision*recall)/(precision+recall)\n",
    "    true_positive_rate = tp/(tp+fn)\n",
    "    false_positive_rate = fp/(fp+tn)\n",
    "\n",
    "    # CODE PROVIDED BY PROFESSOR JACEK --THANKS! :)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot([0, false_positive_rate, 1], [0,\n",
    "    true_positive_rate, 1], color='darkorange',\n",
    "    lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw,\n",
    "    linestyle='--', label='NO SKILL')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC (Receiver operating characteristic) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Error Rate: ' + str(error_rate))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('Specificity: ' + str(specificity))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Negative Predicted Value: ' + str(neg_pred_val))\n",
    "    print('F Score: ' + str(f_score))\n",
    "    print('True Positive: ' + str(tp))\n",
    "    print('True Negative: '+ str(tn))\n",
    "    print('False Positive: '+ str(fp))\n",
    "    print('False Negative: '+ str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(tp, fp, fn, tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f88e3e",
   "metadata": {},
   "source": [
    "# Deep Network Model Comparison\n",
    "### We will compare this against a Deep Network that uses several LSTM layers followed by a a dense layer, followed by another dense layer that predicts using a sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Input\n",
    "from keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "import io\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = training_pos_dataset_list_alpha_cleaned_stemmed\n",
    "train_neg = training_neg_dataset_list_alpha_cleaned_stemmed\n",
    "test_pos = testing_pos_dataset_list_alpha_cleaned_stemmed\n",
    "test_neg = testing_neg_dataset_list_alpha_cleaned_stemmed\n",
    "\n",
    "train_pos_y = np.ones(len(train_pos))\n",
    "train_neg_y = np.zeros(len(train_neg))\n",
    "test_pos_y = np.ones(len(test_pos))\n",
    "test_neg_y = np.zeros(len(test_neg))\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "train_y = np.concatenate((train_pos_y,train_neg_y))\n",
    "test_x = test_pos + test_neg\n",
    "test_y = np.concatenate((test_pos_y,test_neg_y))\n",
    "\n",
    "# val_size = int(len(train_x) * 0.9)\n",
    "# val_x = train_x[val_size:]\n",
    "# train_x = train_x[:val_size]\n",
    "# val_y = train_y[val_size:]\n",
    "# train_y = train_y[:val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5530f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x = []\n",
    "for x in train_x:\n",
    "    sentence = ' '.join(x)\n",
    "    new_train_x.append(sentence)\n",
    "\n",
    "# new_val_x = []\n",
    "# for x in val_x:\n",
    "#     sentence = ' '.join(x)\n",
    "#     new_val_x.append(sentence)\n",
    "\n",
    "new_test_x = []\n",
    "for x in test_x:\n",
    "    sentence = ' '.join(x)\n",
    "    new_test_x.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf113e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000,split=' ')\n",
    "tokenizer.fit_on_texts((new_train_x))\n",
    "# tokenizer.fit_on_texts((new_train_x + new_test_x + new_val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f54dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_json = tokenizer.to_json()\n",
    "with io.open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38475f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x_train = new_train_x[:int(len(new_train_x)/2)]\n",
    "x_train = tokenizer.texts_to_sequences(new_train_x)\n",
    "x_train = pad_sequences(x_train)\n",
    "\n",
    "# x_val = tokenizer.texts_to_sequences(new_val_x)\n",
    "# x_val = pad_sequences(x_val)\n",
    "\n",
    "x_test = tokenizer.texts_to_sequences(new_test_x)\n",
    "x_test = pad_sequences(x_test, maxlen=x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(modelHist):\n",
    "    plt.plot(modelHist.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(modelHist.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c60902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000,128,input_length=x_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "modelHist = model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# modelHist = model.fit(x_train, train_y,validation_data=(x_val, val_y),\n",
    "#           epochs=3,\n",
    "#           batch_size=128, shuffle = True)\n",
    "\n",
    "modelHist = model.fit(x_train, train_y,\n",
    "          epochs=2,\n",
    "          batch_size=128, shuffle = True)\n",
    "\n",
    "model.save('steam_reviews.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc58e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, test_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a85931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(modelHist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The best part about this game is the character creation. If you've been a long time Sonic fan that is most likely what a lot of people initially came for although you honestly don't even get to use them that much. If you REALLY want this game I recommend you wait until it's on sale. At least the soundtrack is great!\"\n",
    "sentence = sentence.lower()\n",
    "new_sentence = []\n",
    "new_sentence.append(''.join([ch for ch in sentence if ch.isalpha() or ch == ' ']))\n",
    "new_sentence = new_sentence[0].split()\n",
    "\n",
    "sentence = [' '.join(new_sentence)]\n",
    "\n",
    "\n",
    "with open('tokenizer.json') as f:\n",
    "    data = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(data)\n",
    "\n",
    "sentence = tokenizer.texts_to_sequences(sentence)\n",
    "sentence = pad_sequences(sentence, maxlen=2000)\n",
    "\n",
    "\n",
    "model = load_model('steam_reviews.h5')\n",
    "predict = model.predict(sentence)\n",
    "print('Is this a positive or negative review?')\n",
    "if predict[0, 0] >= 0.5:\n",
    "    print('This is a positive review')\n",
    "else:\n",
    "    print('This is a negative review')\n",
    "confidence = abs((2*predict[0, 0]) - 1)\n",
    "print('Confidence: ' + str(confidence))\n",
    "print(\"Raw score: \" + str(predict[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve output?\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = model.predict(x_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_y, y_pred_keras)\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Supervised transformation based on random forests\n",
    "rf = RandomForestClassifier(max_depth=3, n_estimators=10)\n",
    "rf.fit(x_train, train_y)\n",
    "\n",
    "y_pred_rf = rf.predict_proba(x_test)[:, 1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(test_y, y_pred_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757154ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix \n",
    "model = load_model('steam_reviews.h5')\n",
    "predict = model.predict(x_test, batch_size=128)\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "for index in range(len(predict)):\n",
    "    \n",
    "\n",
    "    if predict[index, 0] >= 0.5 and test_y[index] == 1:\n",
    "        tp = tp + 1\n",
    "    elif predict[index, 0] >= 0.5 and test_y[index] == 0:\n",
    "        fp = fp + 1\n",
    "    elif predict[index, 0] < 0.5 and test_y[index] == 1:\n",
    "        fn = fn + 1\n",
    "    elif predict[index, 0] < 0.5 and test_y[index] == 0:\n",
    "        tn = tn + 1\n",
    "\n",
    "statistics(tp, fp, fn, tn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
